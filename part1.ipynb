{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d383c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain\n",
    "%pip install -qU \"langchain[groq]\"\n",
    "%pip install python-dotenv\n",
    "%pip install -qU \"langchain[google-genai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f00b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documents\n",
    "question = \"What kind of animals do i like?\"\n",
    "document = \"I like dogs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7e56f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n",
      " kind\n",
      " of\n",
      " animals\n",
      " do\n",
      " i\n",
      " like\n",
      "?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    tokens = encoding.encode(string)\n",
    "    for token in tokens:\n",
    "        print(encoding.decode([token]))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880292b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear cross the road?\n",
      "\n",
      "To get to the other *beary* place!\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "load_dotenv()\n",
    "\n",
    "# Set Groq variables using OpenAI-compatible names\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "response = model.invoke(\"Tell me a joke about bears\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f79e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Basic Crêpes:** Whisk 1 cup flour, 1 1/4 cups milk, 2 eggs, 2 tbsp melted butter, pinch of salt. Cook thin layers on medium heat.\n",
      "\n",
      "**Sweet Crêpes:** Add 1-2 tbsp sugar, 1 tsp vanilla to batter. Serve with fruit, chocolate, or whipped cream.\n",
      "\n",
      "**Savory Crêpes:** Omit sugar. Fill with cheese, ham, vegetables, or eggs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class chef. Limit your reponses to under 30 words.\"),\n",
    "    (\"human\", \"Give me detailed recipes on {topic} \")\n",
    "])\n",
    "\n",
    "test_prommt = prompt.invoke({\"topic\":\"Masala Dosa\"})\n",
    "\n",
    "#Chaining the model and the prompt template\n",
    "chain = prompt|model\n",
    "\n",
    "response = chain.invoke({\"topic\":\"Crepes\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0444b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Wh' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--ec547eaa-0485-471f-8210-cf8b2e22f61c' usage_metadata={'input_tokens': 28, 'output_tokens': 0, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}}|content='isk eggs, season. Hot pan, butter sizzles. Pour eggs, swirl. Tilt' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--ec547eaa-0485-471f-8210-cf8b2e22f61c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}|content=' pan, roll edges. Fill (optional), roll onto plate. Gloss with butter.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--ec547eaa-0485-471f-8210-cf8b2e22f61c' usage_metadata={'input_tokens': 0, 'output_tokens': 38, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}}|"
     ]
    }
   ],
   "source": [
    "for word in chain.stream({\"topic\":\"French Omlette\"}):\n",
    "    print(word, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3acea1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to real-time weather information. To find out the weather in Trivandrum today, I recommend checking a reliable weather app or website such as:\n",
      "\n",
      "*   **Google Weather:** Just search \"weather in Trivandrum\" on Google.\n",
      "*   **AccuWeather:**\n",
      "*   **The Weather Channel:**\n",
      "*   **India Meteorological Department (IMD):** (This is the official source for India)\n",
      "\n",
      "These sources will provide you with the most up-to-date information on temperature, humidity, wind, and any precipitation.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"What is the weather like today in Trivandrum?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92d4d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's calculate the total revenue for Old Ship Saloon in 2023.\\n\\n*   **Q1:** $174,782.38\\n*   **Q2:** $467,372.38\\n*   **Q3:** $474,773.38\\n*   **Q4:** $389,289.23\\n\\n**Total Revenue = Q1 + Q2 + Q3 + Q4**\\nTotal Revenue = $174,782.38 + $467,372.38 + $474,773.38 + $389,289.23 = $1,506,217.37\\n\\n**Therefore, the total revenue earned by Old Ship Saloon in 2023 is $1,506,217.37.**\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "data = \"\"\"\n",
    "Old Ship Saloon 2023 quarterly revenue numbers:\n",
    "Q1: $174782.38\n",
    "Q2: $467372.38\n",
    "Q3: $474773.38\n",
    "Q4: $389289.23\n",
    "\"\"\"\n",
    "\n",
    "data_analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Your job is to act as a data analyst. Dervie financial insights from the information given : {context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain_data_analyst = data_analyst_prompt| model | StrOutputParser()\n",
    "question_input = input(\"Enter your question\")\n",
    "chain_data_analyst.invoke({\"context\": data, \"question\":question_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedec6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
